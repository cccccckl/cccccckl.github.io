<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://cccccckl.github.io</id>
    <title>还是peng哥弔</title>
    <updated>2020-10-25T06:29:03.835Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://cccccckl.github.io"/>
    <link rel="self" href="https://cccccckl.github.io/atom.xml"/>
    <subtitle>blog</subtitle>
    <logo>https://cccccckl.github.io/images/avatar.png</logo>
    <icon>https://cccccckl.github.io/favicon.ico</icon>
    <rights>All rights reserved 2020, 还是peng哥弔</rights>
    <entry>
        <title type="html"><![CDATA[周志 2020/10/19 - 2020/10/25]]></title>
        <id>https://cccccckl.github.io/post/zhou-zhi-20201018-20201025/</id>
        <link href="https://cccccckl.github.io/post/zhou-zhi-20201018-20201025/">
        </link>
        <updated>2020-10-25T05:49:42.000Z</updated>
        <content type="html"><![CDATA[<h1 id="爬虫">爬虫🐞</h1>
<pre><code>#coding = utf - 8
from bs4 import  BeautifulSoup
import re
import urllib.request,urllib.error
date = re.compile(r'&lt;th width=&quot;13%&quot;&gt;(.*?)&lt;/th&gt;')
time = re.compile(r'&lt;th&gt;(.*?)&lt;/th&gt;')
course = re.compile(r'&lt;td&gt;(.*?)&lt;/td&gt;',re.S)

def main() :

    baseurl = &quot;http://run.hbut.edu.cn/ArrangeTask/ClassSchedule?ClassName=&quot;
    getdata(baseurl)

def getdata(baseurl):
    a = input(&quot;年级：&quot;)
    b = input(&quot;班级：&quot;)
    banji = str(a) + &quot;%E8%AE%A1%E7%AE%97%E7%B1%BB&quot; + str(b)
    url = baseurl + banji
    html = askURL(url)
    soup = BeautifulSoup(html, &quot;html.parser&quot;)
    item = soup.find_all(&quot;tr&quot;)
    item = str(item)
    day = re.findall(date,item)
    print(day)
    ti = re.findall(time, item)
    print(ti)
    cour = re.findall(course,item)
    for temp in cour:
        cour = re.sub('&lt;br/&gt;', &quot;&quot;, temp)
        print(cour)


def askURL(url):

    head = {
            &quot;User-Agent&quot;: &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.111 Safari/537.36&quot;
            ,&quot;Cookie&quot;: &quot;ASP.NET_SessionId=hli2lp1udjnxxhue3qyzkonm; userObjFullName=FEeqPDjeGitzgwXDoXySgQ%3d%3d; .ASPXAUTH=9E9DE3B0F22712B6F78C1CB6A8835C8F12E58CA106490A6E14D454E242DEABD3A7A707F0F3D9E2219595F622973C32268596A18F2BCEE14B5D111642ECC604C8A4A57F29C62103387385B009A47E4F0B669817842C37CE74185D0B37EC8EFD84BFA843FCC8009BB09464FCBAAD59BF19A893019AD0F553655B8BACC66891531348269562268679D454420625FFF0F572; Role=lwrt0kLsK1Qv2smKJyYyPtfV1%2bqQu6t6; CurrentSemaster=lwrt0kLsK1R3NGFRCFSX7K9qgkI2IKE4BZ7rn3h6Ay0Vc0IEMt0klA%3d%3d&quot;
            }
    request = urllib.request.Request(url,headers= head)
    response = urllib.request.urlopen(request)
    html = response.read().decode(&quot;utf - 8&quot;)

    return html

if __name__ == &quot;__main__&quot; :
 main()
</code></pre>
<p>这是一个爬课表的爬虫，具体跑起来呢是这样子的<br>
<img src="https://cccccckl.github.io/post-images/1603605312890.png" alt="" loading="lazy"><br>
提供了年纪班级的输入（但是目前只支持计算类- -）<br>
在数据的存储上还没有进一步完善，应该以类来存</p>
<h1 id="机器学习">机器学习</h1>
<h2 id="监督学习">监督学习</h2>
<p>何为监督学习？即我们给算法一个数据集（data set），其中包括了正确答案（“right answer”），而算法的目的就是给出更多的正确答案（more “right answer”）。</p>
<h3 id="回归问题">回归问题</h3>
<p>我们设法预测连续值的属性（continue）。<br>
<img src="https://cccccckl.github.io/post-images/1603606132021.png" alt="" loading="lazy"><br>
以图为例，我们得到一个房价的数据集，在图上寻找其回归方程，或许是直线，或许是曲线，直到我们能够得到一个使数据最收敛的方程。</p>
<h3 id="分类问题">分类问题</h3>
<p>我们设法预测一个离散值输出（discrete）。<br>
<img src="https://cccccckl.github.io/post-images/1603606610984.png" alt="" loading="lazy"><br>
同样以图为例，我们得到某医院中有某种肿瘤的病人的数据，我们所要做的，便是找出一条直线来分离这两类瘤以做预测。</p>
<h2 id="无监督学习">无监督学习</h2>
<p>对于给定数据集，无监督学习算法可能判定该数据集包含多个不同的簇。</p>
<h1 id="周计划">周计划</h1>
<h2 id="本周">本周</h2>
<ul class="contains-task-list">
<li class="task-list-item"><input class="task-list-item-checkbox" checked="" disabled="" type="checkbox" id="task-item-3217972"><label class="task-list-item-label" for="task-item-3217972"> 尝试自己写个爬虫</label>
<ul class="contains-task-list">
<li class="task-list-item"><input class="task-list-item-checkbox" checked="" disabled="" type="checkbox" id="task-item-6705223"><label class="task-list-item-label" for="task-item-6705223"> 开始学习机器学习方面的内容</label></li>
</ul>
</li>
</ul>
<h2 id="下周">下周</h2>
<ul class="contains-task-list">
<li class="task-list-item"><input class="task-list-item-checkbox" disabled="" type="checkbox" id="task-item-5981098"><label class="task-list-item-label" for="task-item-5981098"> 梯度下降</label></li>
<li class="task-list-item"><input class="task-list-item-checkbox" disabled="" type="checkbox" id="task-item-854149"><label class="task-list-item-label" for="task-item-854149"> 代价函数</label></li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[周志   2020/10/12 - 2020/10/18]]></title>
        <id>https://cccccckl.github.io/post/zhou-zhi-20201012-20201018/</id>
        <link href="https://cccccckl.github.io/post/zhou-zhi-20201012-20201018/">
        </link>
        <updated>2020-10-13T08:46:28.000Z</updated>
        <summary type="html"><![CDATA[<ul>
<li>嗯。。。。  方便管理周志 所以搞了个<strong>blog</strong>🕶<br>
<img src="https://cccccckl.github.io/post-images/1602579079211.png" alt="" loading="lazy"></li>
</ul>
<h1 id="正题当然还是来到python爬虫的学习">正题当然还是来到python<em>爬虫</em>的学习</h1>
<p>之前有系统的学习过其他编译型语言，python作为一种解释型语言我觉得还是蛮好理解的，只是其中的一些特有术语（一些库里的函数之类的）会不太清楚（多查点<br>
而我们需要的应该是一个定向爬虫</p>
<h3 id="这是一串正则表达式">这是一串<strong>正则表达式</strong></h3>
<pre><code>findLink = re.compile(r'&lt;a href=&quot;(.*?)&quot;&gt;')            # 创建正则表达式对象，标售规则   影片详情链接的规则
findImgSrc = re.compile(r'&lt;img.*src=&quot;(.*?)&quot;', re.S)
findTitle = re.compile(r'&lt;span class=&quot;title&quot;&gt;(.*)&lt;/span&gt;')
findRating = re.compile(r'&lt;span class=&quot;rating_num&quot; property=&quot;v:average&quot;&gt;(.*)&lt;/span&gt;')
findJudge = re.compile(r'&lt;span&gt;(\d*)人评价&lt;/span&gt;')
findInq = re.compile(r'&lt;span class=&quot;inq&quot;&gt;(.*)&lt;/span&gt;')
findBd = re.compile(r'&lt;p class=&quot;&quot;&gt;(.*?)&lt;/p&gt;', re.S)
</code></pre>
<p>用来匹配网页中的信息，一开始我也好奇为啥要专门搞个这玩意，为啥不用字符串来进行匹配，后面发现一个字符一个字符的查找确实有点离谱，这个是按照某个模式进行匹配，一行代码搞定，方便多了。<br>
<img src="https://cccccckl.github.io/post-images/1602817161593.png" alt="" loading="lazy"><br>
上Google charm F12抓了一下包，看了好久才找到= =。对比上面的代码一看就能发现要爬的是啥数据了。</p>
<pre><code>a = re.compile()  #进行预编译，后续需要大量重复查找操作，使用预编译高效很多
</code></pre>
]]></summary>
        <content type="html"><![CDATA[<ul>
<li>嗯。。。。  方便管理周志 所以搞了个<strong>blog</strong>🕶<br>
<img src="https://cccccckl.github.io/post-images/1602579079211.png" alt="" loading="lazy"></li>
</ul>
<h1 id="正题当然还是来到python爬虫的学习">正题当然还是来到python<em>爬虫</em>的学习</h1>
<p>之前有系统的学习过其他编译型语言，python作为一种解释型语言我觉得还是蛮好理解的，只是其中的一些特有术语（一些库里的函数之类的）会不太清楚（多查点<br>
而我们需要的应该是一个定向爬虫</p>
<h3 id="这是一串正则表达式">这是一串<strong>正则表达式</strong></h3>
<pre><code>findLink = re.compile(r'&lt;a href=&quot;(.*?)&quot;&gt;')            # 创建正则表达式对象，标售规则   影片详情链接的规则
findImgSrc = re.compile(r'&lt;img.*src=&quot;(.*?)&quot;', re.S)
findTitle = re.compile(r'&lt;span class=&quot;title&quot;&gt;(.*)&lt;/span&gt;')
findRating = re.compile(r'&lt;span class=&quot;rating_num&quot; property=&quot;v:average&quot;&gt;(.*)&lt;/span&gt;')
findJudge = re.compile(r'&lt;span&gt;(\d*)人评价&lt;/span&gt;')
findInq = re.compile(r'&lt;span class=&quot;inq&quot;&gt;(.*)&lt;/span&gt;')
findBd = re.compile(r'&lt;p class=&quot;&quot;&gt;(.*?)&lt;/p&gt;', re.S)
</code></pre>
<p>用来匹配网页中的信息，一开始我也好奇为啥要专门搞个这玩意，为啥不用字符串来进行匹配，后面发现一个字符一个字符的查找确实有点离谱，这个是按照某个模式进行匹配，一行代码搞定，方便多了。<br>
<img src="https://cccccckl.github.io/post-images/1602817161593.png" alt="" loading="lazy"><br>
上Google charm F12抓了一下包，看了好久才找到= =。对比上面的代码一看就能发现要爬的是啥数据了。</p>
<pre><code>a = re.compile()  #进行预编译，后续需要大量重复查找操作，使用预编译高效很多
</code></pre>
<!-- more -->
<pre><code>. #点可代表一切字符

\ # 起转义作用

[...] # 指代方括号中的任意字符

\d # 指代数字0-9

\D # 指代非数字

\s # 指代一切空格，包括tab制表符、空格、换行等

\S # 指代非空格

\w # 指代大小写字母、数字和下划线

\W # 指代非大小写字母、数字和下划线

* # 匹配前面字符 &gt;=0 次

+ # 匹配前面字符1次及以上

? # 匹配前面字符0次或1次

{m} # 匹配m次

{m,n} # 匹配m到n次

{m,} # 至少匹配m次
</code></pre>
<h3 id="得到指定一个url的网页内容">得到指定一个URL的网页内容</h3>
<pre><code>def askURL(url):
head = { &quot;User-Agent&quot;: &quot;Mozilla / 5.0(Windows NT 10.0; Win64; x64) AppleWebKit / 537.36(KHTML, like Gecko) Chrome / 80.0.3987.122  Safari / 537.36&quot;
}
# 用户代理，表示告诉豆瓣服务器，我们是什么类型的机器、浏览器（本质上是告诉浏览器，我们可以接收什么水平的文件内容）

request = urllib.request.Request(url, headers=head)
html = &quot;&quot;
try: 
    response = urllib.request.urlopen(request)
    html = response.read().decode(&quot;utf-8&quot;)
except urllib.error.URLError as e:
if hasattr(e, &quot;code&quot;):
    print(e.code)
if hasattr(e, &quot;reason&quot;):
    print(e.reason)
return html
</code></pre>
<p>并不是很懂这段，这段应该是把网页的源码拔下来吧。它咋实现的不是很明白。</p>
<h3 id="爬取网页">爬取网页</h3>
<pre><code>def getData(baseurl):
datalist = []  #用来存储爬取的网页信息
for i in range(0, 10):  # 调用获取页面信息的函数，10次
    url = baseurl + str(i * 25)
    html = askURL(url)  # 保存获取到的网页源码
    # 2.逐一解析数据
    soup = BeautifulSoup(html, &quot;html.parser&quot;)
    for item in soup.find_all('div', class_=&quot;item&quot;):  # 查找符合要求的字符串
        data = []  # 保存一部电影所有信息
        item = str(item)
        link = re.findall(findLink, item)[0]  # 通过正则表达式查找
        data.append(link)
        imgSrc = re.findall(findImgSrc, item)[0]
        data.append(imgSrc)
        titles = re.findall(findTitle, item)
        if (len(titles) == 2):
            ctitle = titles[0]
            data.append(ctitle)
            otitle = titles[1].replace(&quot;/&quot;, &quot;&quot;)  #消除转义字符
            data.append(otitle)
        else:
            data.append(titles[0])
            data.append(' ')
        rating = re.findall(findRating, item)[0]
        data.append(rating)
        judgeNum = re.findall(findJudge, item)[0]
        data.append(judgeNum)
        inq = re.findall(findInq, item)
        if len(inq) != 0:
            inq = inq[0].replace(&quot;。&quot;, &quot;&quot;)
            data.append(inq)
        else:
            data.append(&quot; &quot;)
        bd = re.findall(findBd, item)[0]
        bd = re.sub('&lt;br(\s+)?/&gt;(\s+)?', &quot;&quot;, bd)
        bd = re.sub('/', &quot;&quot;, bd)
        data.append(bd.strip())
        datalist.append(data)
 return datalist
</code></pre>
<p>这一段就开始网页的爬取了</p>
<pre><code>soup = BeautifulSoup(html, &quot;html.parser&quot;)  #对网页进行解析，将html文档解析成文档树，返回bs对象

soup.find_all('div', class_=&quot;item&quot;)  #找到&lt;div class = &quot;item&quot;&gt;
</code></pre>
<!-- more -->
<pre><code>titles = re.findall(findTitle, item)
        if (len(titles) == 2):
            ctitle = titles[0]
            data.append(ctitle)
            otitle = titles[1].replace(&quot;/&quot;, &quot;&quot;)  #消除转义字符
            data.append(otitle)
        else:
            data.append(titles[0])
            data.append(' ')
</code></pre>
<p>这一部分对电影名进行提取，即从下列中进行提取<br>
<img src="https://cccccckl.github.io/post-images/1602828392403.png" alt="" loading="lazy"></p>
<pre><code>bd = re.findall(findBd, item)[0]
bd = re.sub('&lt;br(\s+)?/&gt;(\s+)?', &quot;&quot;, bd)      #消去空格
bd = re.sub('/', &quot;&quot;, bd)
data.append(bd.strip())
</code></pre>
<p>而这一部分则是对下面的相关信息进行处理<br>
<img src="https://cccccckl.github.io/post-images/1602829158225.png" alt="" loading="lazy"></p>
<h3 id="保存数据到表格">保存数据到表格</h3>
<pre><code>def saveData(datalist,savepath):
print(&quot;save.......&quot;)
book = xlwt.Workbook(encoding=&quot;utf-8&quot;,style_compression=0) #创建workbook对象
sheet = book.add_sheet('豆瓣电影Top250', cell_overwrite_ok=True) #创建工作表
col = (&quot;电影详情链接&quot;,&quot;图片链接&quot;,&quot;影片中文名&quot;,&quot;影片外国名&quot;,&quot;评分&quot;,&quot;评价数&quot;,&quot;概况&quot;,&quot;相关信息&quot;)
for i in range(0,8):
    sheet.write(0,i,col[i])  #列名
for i in range(0,250):
    data = datalist[i]
    for j in range(0,8):
        sheet.write(i+1,j,data[j])  #数据
book.save(savepath) #保存
</code></pre>
<p>这一份爬虫代码是从网上copy来的，我想根据里面的一些结构啊，语法啊之类的来学习，边看边写，不会写的时候再回去看，看不懂就去查，就这样一个过程。</p>
<h1 id="周计划">周计划</h1>
<h2 id="本周">本周</h2>
<ul class="contains-task-list">
<li class="task-list-item"><input class="task-list-item-checkbox" checked="" disabled="" type="checkbox" id="task-item-7032852"><label class="task-list-item-label" for="task-item-7032852"> （初步）看懂别人写的爬虫</label>
<ul class="contains-task-list">
<li class="task-list-item"><input class="task-list-item-checkbox" checked="" disabled="" type="checkbox" id="task-item-6679488"><label class="task-list-item-label" for="task-item-6679488"> 机器学习开篇</label></li>
</ul>
</li>
</ul>
<h2 id="下周">下周</h2>
<ul class="contains-task-list">
<li class="task-list-item"><input class="task-list-item-checkbox" disabled="" type="checkbox" id="task-item-7376476"><label class="task-list-item-label" for="task-item-7376476"> 尝试自己写个爬虫</label></li>
<li class="task-list-item"><input class="task-list-item-checkbox" disabled="" type="checkbox" id="task-item-1235288"><label class="task-list-item-label" for="task-item-1235288"> 开始学习机器学习方面的内容</label></li>
</ul>
]]></content>
    </entry>
</feed>